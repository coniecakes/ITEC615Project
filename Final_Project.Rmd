---
title: "Final Project STAT-615"
author: "Maxwell Miller-Golub"
date: "`r Sys.Date()`"
output: 
  html_document:
    code_folding: hide
    number_sections: yes
    includes:
      after_body:
    toc: yes
    toc_float: yes
    code_download: yes
    theme: united
    df_print: kable
---
<style>
/* General text color for the document */
body {
  color: black;
}

/* Specific text size and style classes */
.footnote {
  font-size: 12px;
}

.main-text {
  font-size: 16px;
}

.header-text {
  font-size: 20px;
  font-weight: bold;
}

.section-text {
  font-size: 24px;
  font-weight: bold;
}
</style>
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 1000)
library(tidyverse)
library(readr)
```

```{r data}
# Set current working directory to same folder that houses data file if you haven't done so already.

local_filename <- "Salary Prediction of Data Professions.csv"

Salary_Prediction_of_Data_Professions <- read_csv(local_filename)

view(Salary_Prediction_of_Data_Professions)
```

# Petro's Section

##
Offer a preliminary description of the data set. For example, indicate the size of the data source, describe the variables, and include any other data profile information that would be of interest.

```{r final_project1}
```

##
Generate relevant data visual plots that explore multicollinearity for the quantitative variables and normality for the quantitative variables as well.  Also, use R code to confirm the levels of the categorical variables.

```{r final_project2}
```


##
Using R code, produce a full Regression Model that consists of quantitative and categorical variables.  Make use of the R generated dummy variable matrices 

```{r final_project3}
```



# Max's Section


##
Using only the quantitative variables as predictors, produce a model using matrix methods. Also use matrix methods to find the fitted values and the residuals

```{r final_project4}
# Finding a subsection of the data that is solely quantitative 

quantative_model <- Salary_Prediction_of_Data_Professions %>% 
  select(SALARY, AGE, `PAST EXP`, `LEAVES USED`)

# Eliminating cases with na values to prep for matrix

complete_dataset <- quantative_model[complete.cases(quantative_model),]

quant_model <- lm(SALARY ~ AGE + `PAST EXP` + `LEAVES USED`, data = complete_dataset)
quant_model2 <- lm(SALARY ~ AGE, data = complete_dataset)
#summary(quant_model)
#x <- complete_dataset$AGE
#y <- complete_dataset$SALARY

ggplot(complete_dataset)+
  geom_point(aes(AGE, SALARY))
ggplot(complete_dataset)+
  geom_point(aes(`PAST EXP`, SALARY))

# Age has the highest t value so this is the predictor variable we will use with the matrices

# Creating a matrix for AGE (predictor) with a column of "1s"

quantitative_predictor_with_dummy <- complete_dataset %>% 
  mutate(INTERCEPT = 1) %>% 
  select(INTERCEPT, AGE)
  
x_matrix <- as.matrix(quantitative_predictor_with_dummy)
#head(x_matrix)

# Creating a matrix for the response variable

quantitative_response <- complete_dataset %>% 
  select(SALARY)

y_matrix <- as.matrix(quantitative_response)
#head(y_matrix)

#t(x) -> Transpose of x
#%*% -> row column multiplication
#solve(x) -> inverse of x

# Find Slope and Intercept
solve(t(x_matrix)%*%x_matrix)%*%t(x_matrix)%*%y_matrix -> intercept_and_slope
intercept_and_slope

# Find Residual Values
residuals <- y_matrix -  x_matrix %*% intercept_and_slope
head(residuals)

# Find Fitted values
fitted <- x_matrix %*% intercept_and_slope
head(fitted)

plot(fitted, residuals)
abline(h = 0, col = "blue")
```


##
Produce an output summary table to be used to analyze and evaluate the full model (Adjusted R squared, Standard Error, Significance of Variables, ectâ€¦)

```{r final_project5}
full_model_prep <- Salary_Prediction_of_Data_Professions %>% 
  select(SALARY, AGE, SEX, DESIGNATION, UNIT, `PAST EXP`, `LEAVES USED`, RATINGS)

full_model <- lm(SALARY ~ AGE + SEX + DESIGNATION + UNIT + `PAST EXP` + `LEAVES USED` + RATINGS, data = full_model_prep)
summary(full_model)
```
Age (p < 0.05) and Job Designation (p < 0.00001) are both statistically significant, indicating a very high probability that the change seen in the response (salary) is not due to chance alone.

##
Use procedures and techniques explored in class to produce confidence intervals for the independent quantitative variables of your model. Choose at least two of the quantitative variables to find confidence intervals for.

```{r final_project6}
# calculation t scores
qt(p = 0.025, df = 2632 , lower.tail = FALSE) -> t_score

# calculate Past Exp confidence intervals
past_exp_UB <- -260.78 + t_score*154.69
past_exp_LB <- -260.78 - t_score*154.69

# calculate Age confidence interval
age_UB <- 285.76 + t_score*144.59
age_LB <- 285.76 - t_score*144.59
```

# Conie's Section


##
Now produce a reduced model (removing variables of your choice with justification). Use R summary coding for both models and offer justification for choosing one model over the other.

```{r final_project7}
# review summary statistics of full model
summary(full_model)

# build reduced model
reduced_model <- lm(SALARY ~ DESIGNATION + AGE, data = full_model_prep)

#review summary statistics of reduced model
summary(reduced_model)

# confirm with stepwise regression
sw_intercept <- lm(SALARY ~ 1, data = full_model_prep)
sw_intercept

sw_all <- full_model

sw_forward <- step(sw_intercept, direction = 'forward', scope = formula(sw_all), trace = 0)
sw_forward$anova
```

After reviewing the summary statistics of the full model, we can remove the variables Unit, Past Exp, Leaves Used, and Sex because none are statistically significant. For all variables, p > 0.05. We can reduce the model to include only Age and Designation, who are significant because p < 0.05 in the full model. After reducing the model, we see that the only significant variable is Designation - Age now has p > 0.05. After running a stepwise regression to confirm the outputs, our final reduced model only includes the indicator variable Designation.


##
Research and apply a model analysis technique not discussed in class to your full model or reduced model.  Fully explain the technique or procedure and how it is being applied to your specific model.

```{r final_project8}

```


##
Offer final summary perspectives about the data and the models that you produce, suggesting how your models or model analysis enhanced your understanding of the data. (4 or 5 sentences)

<center>Our Changing Perspectives</center>
Our first full model gives us a wide view of the data and includes a number of variables that we would conventionally associate with salary, like Age, Sex, Past Experience, Designation. After analyzing the summary statistics of the data, we can see that most of these variables are not statistically significant to predicting the salaries of data science professionals from this data set. Even after keeping the statistically significant variables, our reduced model proved to eliminate further variables, leaving only Designation as a statistically significant predictor of salary. 
<br><br>
<center>What does this mean?</center>
This means that our data set is potentially too narrow. Even though we have over 2600 entries, this may not be a large enough sample size to overcome the effects of the designation variable. In a deeper investigation, we may need to gather data from other sources to see if the Designation (which we may term as any sort of job level variable) is a powerful indicator across the board in this industry, or if this is a result of our data selection.
